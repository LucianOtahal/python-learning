{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a606b7c-5840-4f34-9061-c34aade623d9",
   "metadata": {},
   "source": [
    "# PYTHON FINAL WORKSHOP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768107ff-6747-40c3-b030-63bd60f8324c",
   "metadata": {},
   "source": [
    "# Project structure:\n",
    "- data/\n",
    "  - raw/         ← downloaded HTML files\n",
    "  - interim/     ← extracted data to json file\n",
    "  - processed/   ← final dataset\n",
    "- notebooks/     ← Jupyter notebooks\n",
    "- drivers/       ← chromedriver.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ec9e48-9833-44b7-ac2e-56a35b0cc347",
   "metadata": {},
   "source": [
    "# File: 01 Data Download\n",
    "\n",
    "The first step is to obtain the necessary data for analysis. We are working with [https://www.scrapethissite.com/pages/forms/](https://www.scrapethissite.com/pages/forms/). To fetch the website content, I used the `requests` and `BeautifulSoup` Python libraries.\n",
    "\n",
    "Next, I located the data of interest — the table containing team names and relevant statistics. I did this using the BeautifulSoup library, specifically with CSS selectors and the `soup.select()` function.\n",
    "\n",
    "I then iterated over the list of teams using a loop to extract all the data from the table.I have only used the function (print) to display the results. \n",
    "\n",
    "Finally, I used the `os` library (Operating System interface) to create a folder on my computer where the raw HTML data is stored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb0791a-de2f-4e74-9e74-0f5a32e507b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# File 02: Data Processing\n",
    "Next, the task was to convert html file to json,  based on data from files located in the /data/raw directory, which were generated in the previous stage.\n",
    "Each collected record should be organized into a dictionary with the structure shown below and then added to the results list:\n",
    "\n",
    "{  \n",
    "    'Team Name': 'Boston Bruins',  \n",
    "    'Year': '1990',  \n",
    "    'Wins': '44',  \n",
    "    'Losses': '24',  \n",
    "    'OT Losses': '',  \n",
    "    'Win %': '0.55',  \n",
    "    'Goals For (GF)': '299',  \n",
    "    'Goals Against (GA)': '264',  \n",
    "    '+ / -': '35' \n",
    "\n",
    "I have started with importing the json, BeautifulSoup and glob libraries.\n",
    "Regarding glob, I have not used it much, as there was only one html file to load). \n",
    "Then, I have prepared an empty list team_data = [], ready to be filled with dictionaries (teams). I have then used the same loop as in File 01, only with the difference that I have saved the results in the [team_data]list. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee7d8f8-04e2-4cac-9c63-be5619de8583",
   "metadata": {},
   "source": [
    "# File 03: Data Analysis\n",
    "For data analysis, I started with importing the pandas, matplotlib and pyplot libraries. \n",
    "It was recommended to load the data into a variable with a suffix _raw, so I did so: \n",
    "\"df_raw=pd.read_json(\"../data/interim/hockey_teams.json\"\n",
    "Then, I used the json library (import json), opened the file with json.load() as f and loaded all the data into a variable called \"data\". \n",
    "\n",
    "Next, I renamed the column names. I then created a working copy of the whole dataframe (df=df_raw.copy()). \n",
    "\n",
    "\n",
    "The following four steps explore how to handle empty values and convert columns to numeric types.\n",
    "**Step 1: Inspect how empty or invalid values are represented**\n",
    "```python\n",
    "print(df[\"overtime_defeats\"].unique())\n",
    "This helps identify problematic entries such as empty strings (''), dashes ('—'), or other non-numeric placeholders.\n",
    "Step 2: Replace empty strings with zero\n",
    "df.replace('', 0, inplace=True)\n",
    "This assumes that empty strings represent missing numeric values and that zero is a meaningful default.\n",
    "Step 3: Convert values to numeric types \n",
    "df[\"overtime_defeats\"] = pd.to_numeric(df[\"overtime_defeats\"], errors=\"coerce\") \n",
    "In practice, I applied this conversion to all numeric columns to ensure consistent data types and detect any remaining invalid entries. \n",
    "Step 4: (Optional) Check for missing values after conversion\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Dataset Analysis\n",
    "Here, the first task was to find out how many teams have participated: print(df[\"team\"].nunique()). I found out that there were total of 35 teams. \n",
    "How many unique season were included in the dataset? df[\"season\"].nunique() - 21 unique seasons. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4178c4c4-53f4-45ea-b2f7-50c69945aff5",
   "metadata": {},
   "source": [
    "# File 03: Data Analysis - continued\n",
    "However, it was necessary to check whether we have data for all the seasons. \n",
    "I did this by creating a list of all years (all_years = list(range(df[\"season\"].min(), df[\"season\"].max() + 1)).\n",
    "Then, I created a list of years actually present in the dataset (present_years = sorted(df[\"season\"].dropna().unique())\n",
    "In order to compare these two lists, I used list comprehention [year for year in all_years if year not in present_years]. \n",
    "Using the print () function, I found out that the missing season is 2004. \n",
    "\n",
    "The following part of data analysis included analysis of numerical values. \n",
    "We analyzed team participation in league seasons - e.g. how many teams were there that played in all seasons? \n",
    "We found the top 10 best playing teams, as well as those who lost most frequently. \n",
    "In conclusion, we generated the distribution of goals ratio using the plt.hist function from the matplotlib library, performing the task in two variants:\n",
    "\n",
    "with the number of bins determined using Rice's Rule,\n",
    "with the number of bins determined using the Square Root Rule.\n",
    "\n",
    "                                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a475864d-84f3-475d-a772-42380e4c9314",
   "metadata": {},
   "source": [
    "# File 04: Business recommendations\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
